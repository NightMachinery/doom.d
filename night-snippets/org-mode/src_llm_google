# -*- mode: snippet -*-
# name: llm-google
# key: <lg
# uuid: <lg
# --
#+begin_src jupyter-python :kernel py_base :session llm_1 :async yes :exports both
res = openai_chat_complete(
    ##
    # model="OR:anthropic/claude-3.5-sonnet:beta",
    # model="OR:google/gemini-pro-1.5-exp",
    # model="OR:google/gemini-pro-1.5",
    # model="GAI:gemini-1.5-pro-002",
    # model="GAI:gemini-exp-1114",
    model="GAI:gemini-2.5-pro-exp-03-25",
    ##
    messages=[
        # {"role": "system", "content": """Output your changes in the unified diff format. When appropriate, refactor so that you don't repeat yourself (DRY)."""},
        {"role": "user", "content": r"""
`%`$0
        """},
    ],
    temperature=0,
    max_tokens=4000,
    interactive=True,
)

print_chat_streaming(res, copy_mode=None) # "chat2"
bell_gpt()
#+end_src
